---
title: 记录：Deepseek V3.1的长上下文幻觉
published: 2025-09-21
description: ''
image: ''
tags: ['ai', '上下文']
category: '技术'
draft: false 
lang: ''
---

## 起因

在C项目中，日常API使用的是gemini的 2.5 flash模型（1000k上下文），日常的对话能够正常处理

有一天，gemini的API访问出现问题，所以临时换用Deepseek V3.1模型（128k上下文），一般的对话的语言风格有所变化，不过仍能正常回答和聊天

但是当群内积累的消息过多时，上下文的知识便开始崩坏：**最开始的System Prompt的设定开始遗忘，回答问题开始趋向于模型本身的风格** 、 **开始出现对问题的答非所问**

近乎无法正常使用的状态，当上下文清除后，又能够正常运行

## 分析

群内消息的数量逐渐积累，上下文信息越来越多。由于没有使用知识库和重排序的策略，Deepseek V3.1 模型在接近上下文上限时，可能会发生数据截断，比如忘记system prompt的设定，这对于服务模型是致命性的。

而gemini稳定的原因，当然超大的上下文功不可没，但除此之外，可能的原因推测为，gemini在回答问题后会自己维护一个轻量的对话知识库，采用小模型来进行嵌入和重排序，以此来提高稳定性。由于gemini没有开源，只能做一个合理的推测

（图略）（存在主观成分）